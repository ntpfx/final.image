{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\GITHUB\\final.image/camera_params/\n",
      "[[726.47630219   0.         466.25758541]\n",
      " [  0.         732.0640605  251.997867  ]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "params_dir = os.getcwd()+'/camera_params/' #Calibration -> Parallel image \n",
    "print(params_dir)\n",
    "# Load camera parameters\n",
    "ret = np.load(params_dir+'ret.npy')\n",
    "K = np.load(params_dir+'K.npy')\n",
    "dist = np.load(params_dir+'dist.npy')\n",
    "focal_length = (K[0,0] + K[1,1])/2\n",
    "\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare stereo matching variables\n",
    "#This section student has to do fine tunes by yourself for max_disp\n",
    "win_size = 5\n",
    "min_disparity = -1\n",
    "max_disparity = 63\n",
    "num_disparity = max_disparity - min_disparity #Must be divisible by 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo = cv2.StereoSGBM_create(\n",
    "    minDisparity = min_disparity, \n",
    "    numDisparities = num_disparity,\n",
    "    blockSize = 20,\n",
    "    uniquenessRatio = 1,\n",
    "    speckleWindowSize = 20,\n",
    "    speckleRange = 5,\n",
    "    disp12MaxDiff = 2,\n",
    "    P1 = 8*3*win_size**2,\n",
    "    P2 = 32*3*win_size**2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling_image(image, reduction_scale) : # Reduce image resolution Pyr lelel\n",
    "    for i in range(0, reduction_scale) :\n",
    "        if len(image.shape) > 2:\n",
    "            row, col = image.shape[:2]\n",
    "        else :\n",
    "            row, col = image.shape\n",
    "        \n",
    "        image = cv2.pyrDown(image,dstsize=(col//2,row//2))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessimg(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return (img, img_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpening(img):\n",
    "    kernel = np.array([ [0, 0, 0],\n",
    "                        [0, 2, 0],\n",
    "                        [0, 0, 0] ])\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    return (img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(img):\n",
    "    img = cv2.GaussianBlur(img,(9,9),cv2.BORDER_DEFAULT)\n",
    "    \n",
    "    return (img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = cv2.imread(\"./images/template/Template-1.png\")\n",
    "template = smoothing(template)\n",
    "template_img,template_gray = preprocessimg(template)\n",
    "sift = cv2.SIFT_create()\n",
    "bf = cv2.BFMatcher()\n",
    "# cv2.imshow(\"AAA\",template_gray)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natta\\AppData\\Local\\Temp\\ipykernel_7500\\2627957093.py:37: RuntimeWarning: divide by zero encountered in divide\n",
      "  z = focal_length/disparity_map\n"
     ]
    }
   ],
   "source": [
    "left_cap = cv2.VideoCapture('./video/final_exam/Dataset-1/left_output-1.avi')\n",
    "right_cap = cv2.VideoCapture('./video/final_exam/Dataset-1/right_output-1.avi')\n",
    "\n",
    "ret ,left_vid = left_cap.read() # You have to read left and right together for syncing the video frame\n",
    "ret ,right_vid = right_cap.read() \n",
    "\n",
    "h, w = left_vid.shape[:2]\n",
    "\n",
    "#Get the new optimal camera matrix for better undistortion\n",
    "new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(K, dist, (w,h),1, (w,h))\n",
    "\n",
    "\n",
    "while left_cap.isOpened() and right_cap.isOpened() :\n",
    "    ret_left ,left_vid = left_cap.read() # You have to read left and right together for syncing the video frame\n",
    "    ret_right ,right_vid = right_cap.read() \n",
    "    \n",
    "    if ret_left and ret_right :\n",
    "        left_vid_gray = cv2.cvtColor(left_vid,cv2.COLOR_BGR2GRAY)\n",
    "        right_vid_gray = cv2.cvtColor(right_vid,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #Undistort image\n",
    "        left_vid_undistorted = cv2.undistort(left_vid_gray, K, dist, None, new_camera_matrix)\n",
    "        right_vid_undistorted = cv2.undistort(right_vid_gray, K, dist, None, new_camera_matrix)\n",
    "\n",
    "        #Downsampling each image 1 pyramid level in order to improve computational speed\n",
    "        left_vid_down = downsampling_image(left_vid_undistorted,1)\n",
    "        right_vid_down = downsampling_image(right_vid_undistorted,1)\n",
    "\n",
    "\n",
    "        disparity_map = stereo.compute(left_vid_down, right_vid_down) # Range 0-2 -> 8bits 0-255\n",
    "        norm_disp = cv2.normalize(disparity_map, None , alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "        row, col = norm_disp.shape[:2]\n",
    "        norm_disp = cv2.pyrUp(norm_disp,dstsize=(col*2, row*2))\n",
    "        dist_hsv = cv2.applyColorMap(norm_disp,cv2.COLORMAP_JET)\n",
    "\n",
    "        z = focal_length/disparity_map\n",
    "        z = cv2.resize(z,(left_vid.shape[1],left_vid.shape[0]))\n",
    "\n",
    "        sharp_left_vid = sharpening(left_vid)\n",
    "        sharp_left_vid_gray = cv2.cvtColor(sharp_left_vid,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        template_kpts , template_desc = sift.detectAndCompute(template_gray,None)\n",
    "        query_kpts , query_desc = sift.detectAndCompute(sharp_left_vid_gray,None)\n",
    "        matches = bf.knnMatch(template_desc,query_desc,k=2)\n",
    "\n",
    "\n",
    "        good_matches = list()\n",
    "        good_matches_list = list()\n",
    "        for m,n in matches:\n",
    "            if m.distance <0.7*n.distance :\n",
    "                good_matches.append(m)\n",
    "                good_matches_list.append([m])\n",
    "\n",
    "        min_match_number = 10\n",
    "        if len(good_matches) > min_match_number:\n",
    "            src_pts = np.float32([template_kpts[m.queryIdx].pt for m in good_matches]).reshape(-1,1,2)\n",
    "            dst_pts = np.float32([query_kpts[m.trainIdx].pt for m in good_matches]).reshape(-1,1,2)\n",
    "\n",
    "            H, inlier_masks = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC) # H RANSAC\n",
    "\n",
    "            h_template,w_template = template_img.shape[:2]\n",
    "            template_box = np.float32([[0, 0] , [0, h_template-1] , [w_template-1, h_template-1] , [w_template-1, 0]]).reshape(-1,1,2)\n",
    "            transformed_box = cv2.perspectiveTransform(template_box, H)\n",
    "\n",
    "            cX = ((transformed_box[0,0][0] + transformed_box[2,0][0])/2).astype(int)\n",
    "            cY = ((transformed_box[0,0][1] + transformed_box[2,0][1])/2).astype(int)\n",
    "\n",
    "            X = (cX*z[cY,cX])/focal_length\n",
    "            Y = (cY*z[cY,cX])/focal_length\n",
    "            Z = z[cY,cX]\n",
    "\n",
    "\n",
    "\n",
    "            detected_vid = cv2.polylines(left_vid, [np.int32(transformed_box)], True, (255,0,0), 3, cv2.LINE_AA)\n",
    "            text = 'X:{:.1f} Y:{:.1f} Z:{:.1f}'.format(X-0.5,Y-0.5,Z)\n",
    "            cv2.putText(detected_vid,text,(cX,cY),cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow('Video frame', detected_vid)\n",
    "        else: \n",
    "            cv2.imshow('Video frame', left_vid)\n",
    "\n",
    "        if cv2.waitKey(int(1000/30)) & 0xFF == ord('q') : # this line control the period between image frame\n",
    "            break\n",
    "    else :\n",
    "        break\n",
    "\n",
    "left_cap.release()\n",
    "right_cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59c2cff008705844545e81e13985dd53ac344a221d3095bc517ee3b75bd88638"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
